{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f78533-c1e8-49cb-99db-02f8342b5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Used to measure execution time of code segments\n",
    "import pandas as pd  # Primary data structure library for data manipulation and analysis\n",
    "import numpy as np  # Library for support to large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays\n",
    "from sqlalchemy import create_engine  # Database toolkit for Python, provides a way to create a connection to the database\n",
    "import re  # Library for regular expression operations, allows for text searching, matching, and manipulation\n",
    "from scipy import stats  # Module in SciPy library for statistical functions\n",
    "\n",
    "import nltk  # Natural Language Toolkit, library for symbolic and statistical natural language processing (NLP)\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])  # Downloads specific packages from NLTK for tokenization, lemmatization, and stopwords\n",
    "from nltk.tokenize import word_tokenize  # Function for tokenizing strings (splitting strings into words and punctuation)\n",
    "from nltk.corpus import stopwords  # Provides a list of 'stopwords' that can be filtered out from the text\n",
    "from nltk.stem import WordNetLemmatizer  # Class for lemmatizing words (reducing them to their base or root form)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV  # Functions and classes for splitting data, cross-validation, and hyperparameter tuning\n",
    "from sklearn.pipeline import Pipeline  # Class for creating a pipeline of transforms with a final estimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer  # Classes for converting text to vector form and applying TF-IDF transformation\n",
    "from sklearn.decomposition import TruncatedSVD  # Class for dimensionality reduction using truncated singular value decomposition (SVD)\n",
    "from sklearn.multioutput import MultiOutputClassifier  # Strategy for multi-target classification\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision tree classifier\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random forest classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # K-nearest neighbors classifier\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression classifier\n",
    "from sklearn.svm import SVC  # Support vector machine classifier\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score  # Functions for calculating common classification metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignores warnings to clean up output for readability\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Recreate the original 'genres' list from Algorithm.py to set up current environment \n",
    "# Ensure current environment mirrors the training setup for model deserialization process\n",
    "engine = create_engine('sqlite:///dialogue.db')  # Creates a connection to the SQLite database file `dialogue.db`\n",
    "df = pd.read_sql('dialogue', engine)  # Loads the 'dialogue' table from the database into a DataFrame\n",
    "\n",
    "genres = df['genres'].tolist()  # Converts the 'genres' column to a list\n",
    "genres = ','.join(genres)  # Joins all genre strings into a single string separated by commas\n",
    "genres = genres.split(',')  # Splits the single string back into a list of genres, effectively flattening the list\n",
    "genres = sorted(list(set(genres)))  # Removes duplicates and sorts the genres\n",
    "\n",
    "#Original custom tokenize function from Algorithm.py for joblib to use as part of model deserialization process\n",
    "def tokenize(text):\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)  # Replaces all characters not in a-zA-Z0-9 with a space\n",
    "    tokens = word_tokenize(text)  # Tokenizes the cleaned text\n",
    "    lemmatizer = WordNetLemmatizer()  # Initializes the WordNet lemmatizer\n",
    "    clean_tokens = (lemmatizer.lemmatize(token).lower().strip() for token in tokens if token \\\n",
    "                    not in stopwords.words('english'))  # Lemmatizes, converts to lowercase, strips whitespace, and removes stopwords from the tokens\n",
    "    return clean_tokens  # Returns the cleaned tokens\n",
    "    \n",
    "#load the trained model\n",
    "model = load('CinemAiModel.joblib')\n",
    "\n",
    "# function that utilizes trained model for prediction of new data\n",
    "def predict_genres(text):\n",
    "    pred = pd.DataFrame(model.predict([text]), columns = genres)  # Predicts the genres for a given text input\n",
    "    pred = pred.transpose().reset_index()  # Transposes the prediction DataFrame for easier manipulation\n",
    "    pred.columns = ['genre', 'prediction']  # Renames columns for clarity\n",
    "    predictions = pred[pred['prediction'] == 1]['genre'].tolist()  # Extracts the genres predicted as present (1)\n",
    "    return predictions  # Returns the list of predicted genres\n",
    "\n",
    "line1 = \"If god did not exist it would be necessary to invent him.\"  # Example line of dialogue for testing\n",
    "line2 = \"It's funny... the world is so different in the daylight. In the dark, your fantasies get so out of hand. \\\n",
    "But in the daylight everything falls back into place again.\"  # Another example line of dialogue for testing\n",
    "print('Line 1: {}'.format(predict_genres(line1)))  # Prints genres predicted for line1\n",
    "print('Line 2: {}'.format(predict_genres(line2)))  # Prints genres predicted for line2\n",
    "\n",
    "line  = ''  # Initializes an empty string\n",
    "while line != 'exit':  # Continues to prompt for input until 'exit' is entered\n",
    "    line = input(\"Enter a line of text: \")  # Prompts user for a line of text\n",
    "    print('Genre: {}'.format(predict_genres(line)))  # Prints the predicted genres for the entered text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
